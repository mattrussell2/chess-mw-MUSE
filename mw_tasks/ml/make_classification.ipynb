{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nback - 2933\n",
      "stroop - 2759\n",
      "(2137, 20) - (2137,) - (796, 20) - (796,)\n",
      "[LightGBM] [Info] Number of positive: 1162, number of negative: 975\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 2137, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.543753 -> initscore=0.175460\n",
      "[LightGBM] [Info] Start training from score 0.175460\n",
      "(2009, 20) - (2009,) - (750, 20) - (750,)\n",
      "[LightGBM] [Info] Number of positive: 996, number of negative: 1013\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 2009, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495769 -> initscore=-0.016924\n",
      "[LightGBM] [Info] Start training from score -0.016924\n",
      "(4259, 20) - (4259,) - (2134, 20) - (2134,)\n",
      "[LightGBM] [Info] Number of positive: 2115, number of negative: 2144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 4259, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496595 -> initscore=-0.013618\n",
      "[LightGBM] [Info] Start training from score -0.013618\n",
      "(4146, 20) - (4146,) - (1546, 20) - (1546,)\n",
      "[LightGBM] [Info] Number of positive: 2167, number of negative: 1979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 4146, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.522672 -> initscore=0.090752\n",
      "[LightGBM] [Info] Start training from score 0.090752\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nback</th>\n",
       "      <th>stroop</th>\n",
       "      <th>all</th>\n",
       "      <th>nback + stroop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.582610</td>\n",
       "      <td>0.541035</td>\n",
       "      <td>0.541767</td>\n",
       "      <td>0.571697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>0.494962</td>\n",
       "      <td>0.524316</td>\n",
       "      <td>0.506786</td>\n",
       "      <td>0.514718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.811558</td>\n",
       "      <td>0.622612</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>0.721833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.722235</td>\n",
       "      <td>0.563720</td>\n",
       "      <td>0.586736</td>\n",
       "      <td>0.645436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann</th>\n",
       "      <td>0.752793</td>\n",
       "      <td>0.572552</td>\n",
       "      <td>0.593556</td>\n",
       "      <td>0.665384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbm</th>\n",
       "      <td>0.766330</td>\n",
       "      <td>0.581159</td>\n",
       "      <td>0.634233</td>\n",
       "      <td>0.669280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>0.822851</td>\n",
       "      <td>0.579083</td>\n",
       "      <td>0.647697</td>\n",
       "      <td>0.701002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.816564</td>\n",
       "      <td>0.576610</td>\n",
       "      <td>0.656576</td>\n",
       "      <td>0.712456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nback    stroop       all  nback + stroop\n",
       "svc       0.582610  0.541035  0.541767        0.571697\n",
       "log_reg   0.494962  0.524316  0.506786        0.514718\n",
       "rf        0.811558  0.622612  0.660661        0.721833\n",
       "knn       0.722235  0.563720  0.586736        0.645436\n",
       "ann       0.752793  0.572552  0.593556        0.665384\n",
       "gbm       0.766330  0.581159  0.634233        0.669280\n",
       "lightgbm  0.822851  0.579083  0.647697        0.701002\n",
       "xgboost   0.816564  0.576610  0.656576        0.712456"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, \\\n",
    "                             AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from merf import MERF\n",
    "from library import *\n",
    "\n",
    "import itertools\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('WLOAD_notch_bp_avg_mastoid_annotated_ica_fft.csv')\n",
    "\n",
    "df['trial_id'] = df['trial_id'].apply(lambda x: x[2:-2])\n",
    "\n",
    "\n",
    "# -1 trials are not used [first three for nback and/or rest, etc.]\n",
    "df = df[df['workload'] != '-1']\n",
    "\n",
    "# 'True'/'False' is used by stroop, whereas 0,1,2,3 are used for nback and rotation\n",
    "df['workload'] = df['workload'].apply(lambda x: '3.0' if x == 'True' else '0.0' if x == \"False\" else x)\n",
    "df['workload'] = df['workload'].astype(float).astype(int)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if row['workload'] == 1:        \n",
    "        df['workload'][i] = 0\n",
    "    elif row['workload'] == 2 or row['workload'] == 3:\n",
    "        df['workload'][i] = 1\n",
    "\n",
    "# DROP ROTATION FOR NOW.\n",
    "\n",
    "all_results = {'nback': [], 'stroop': [], 'all': []}\n",
    "trial_types = ['nback', 'stroop']\n",
    "\n",
    "# Generate all combinations of two trial types\n",
    "combinations = list(itertools.combinations(trial_types, 2))\n",
    "\n",
    "# Add combinations to the results dictionary\n",
    "for combo in combinations:\n",
    "    all_results[' + '.join(combo)] = []\n",
    "\n",
    "for key in ['nback', 'stroop']:\n",
    "    print(f\"{key} - {df[df['trialtype'] == key].shape[0]}\")\n",
    "\n",
    "size_stroop = df[df['trialtype'] == 'stroop'].shape[0]\n",
    "\n",
    "for option in all_results.keys():\n",
    "    \n",
    "    if option == 'all':\n",
    "        subdf = df.copy()\n",
    "    elif option in trial_types:\n",
    "        subdf = df[df['trialtype'] == option]\n",
    "    else:\n",
    "        # For combinations, concatenate the dataframes\n",
    "        types = option.split(' + ')\n",
    "        subdf = pd.concat([df[df['trialtype'] == t] for t in types])\n",
    "\n",
    "    freqd = produce_freq_bands(subdf)\n",
    "    X_train, X_test, y_train, y_test = split_data(freqd)\n",
    "    X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "        \n",
    "    results = classify(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    all_results[option].append(results)\n",
    "    \n",
    "results = pd.concat({key: pd.concat(val).T for key, val in all_results.items()}, axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def undersample_dataset(X, y, size, random_state=42):\n",
    "    X_undersampled, y_undersampled = resample(X, y, replace=False, n_samples=size, random_state=random_state)\n",
    "    return X_undersampled, y_undersampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation\txgboost\t   0.6287\n",
    "Nback\t    lightgbm   0.8229\n",
    "Stroop\t    rf\t       0.6213\n",
    "All\t        rf\t       0.6719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def produce_freq_bands(df):\n",
    "\n",
    "    # Define the frequency bands\n",
    "    freq_bands = {\n",
    "        \"Delta\": (0.5, 4),\n",
    "        \"Theta\": (4, 8),\n",
    "        \"Alpha\": (8, 14),\n",
    "        \"Beta\":  (14, 30),\n",
    "        \"Gamma\": (30, 45)\n",
    "    }\n",
    "\n",
    "    # Extract only the columns with frequency data\n",
    "    freq_data = df.filter(like=\"freq\")\n",
    "\n",
    "    binned_df = pd.DataFrame()\n",
    "\n",
    "    for ch in range(4):  # Assuming you have 4 channels: ch_0, ch_1, ch_2, ch_3\n",
    "        for band, (f_min, f_max) in freq_bands.items():\n",
    "            # Filter columns for the current channel and band\n",
    "            cols = [col for col in freq_data.columns \n",
    "                    if f\"ch_{ch}_freq_\" in col \n",
    "                    and f_min <= float(col.split(\"_\")[3][:-2]) <= f_max]\n",
    "            \n",
    "            # Aggregate the columns and add to the binned dataframe\n",
    "            if cols:\n",
    "                binned_df[f\"ch_{ch}_{band}\"] = freq_data[cols].mean(axis=1)\n",
    "            else:\n",
    "                binned_df[f\"ch_{ch}_{band}\"] = np.nan\n",
    "\n",
    "    # Add back non-frequency columns to the binned dataframe\n",
    "    for col in ['trialtype', 'correct', 'workload', 'pid', 'trial_id', 'filename']:\n",
    "        binned_df[col] = df[col]\n",
    "\n",
    "    df = binned_df\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "within subjects test; make sure to separate data into EITHER test/train based on which file produced the data. technically could get more specific with nback task, but this is generalizable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def split_data(df):\n",
    "\n",
    "    X = df.drop(columns=['trialtype', 'correct', 'workload', 'pid', 'trial_id', 'filename'])\n",
    "    y = df['workload']\n",
    "    pid = df['pid']\n",
    "\n",
    "    # Initial split based on pid\n",
    "    X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "\n",
    "    # Iterate over each unique pid\n",
    "    for unique_pid in pid.unique():\n",
    "\n",
    "        # Filter data for the current pid\n",
    "        pid_data = df[df['pid'] == unique_pid]\n",
    "        \n",
    "        X_pid = pid_data.drop(columns=['trialtype', 'correct', 'workload', 'pid', 'trial_id', 'filename'])\n",
    "        y_pid = pid_data['workload']\n",
    "        group_pid = pid_data['filename']\n",
    "        \n",
    "        # Use GroupShuffleSplit to split data based on filename for the current pid\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "        train_idx, test_idx = next(gss.split(X_pid, y_pid, groups=group_pid))\n",
    "        \n",
    "        X_train_list.append(X_pid.iloc[train_idx])\n",
    "        X_test_list.append(X_pid.iloc[test_idx])\n",
    "        y_train_list.append(y_pid.iloc[train_idx])\n",
    "        y_test_list.append(y_pid.iloc[test_idx])\n",
    "\n",
    "    # Concatenate the results to get the final train and test sets\n",
    "    X_train = pd.concat(X_train_list)\n",
    "    X_test = pd.concat(X_test_list)\n",
    "    y_train = pd.concat(y_train_list)\n",
    "    y_test = pd.concat(y_test_list)\n",
    "\n",
    "    print(f\"{X_train.shape} - {y_train.shape} - {X_test.shape} - {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "def classify(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    models = {  \n",
    "                'svc': SVC(), \n",
    "                'log_reg': LogisticRegression(max_iter=10000), \n",
    "                'rf': RandomForestClassifier(), \n",
    "                'knn': KNeighborsClassifier(n_neighbors=5),  # Start with 5 neighbors, \n",
    "                'ann': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=10000),  # Simple 2-layer feedforward network,\n",
    "                'gbm': GradientBoostingClassifier(), \n",
    "                'lightgbm': lgb.LGBMClassifier(), \n",
    "                'xgboost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "            }\n",
    "\n",
    "    results = {model: None for model in models.keys()}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')    \n",
    "        results[model_name] = f1\n",
    "\n",
    "    results = pd.Series(results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try participant based split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55       367\n",
      "           1       0.50      0.45      0.47       345\n",
      "\n",
      "    accuracy                           0.51       712\n",
      "   macro avg       0.51      0.51      0.51       712\n",
      "weighted avg       0.51      0.51      0.51       712\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.82      0.61       320\n",
      "           1       0.65      0.28      0.39       381\n",
      "\n",
      "    accuracy                           0.53       701\n",
      "   macro avg       0.57      0.55      0.50       701\n",
      "weighted avg       0.58      0.53      0.49       701\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.44      0.50       358\n",
      "           1       0.53      0.67      0.59       336\n",
      "\n",
      "    accuracy                           0.55       694\n",
      "   macro avg       0.56      0.56      0.55       694\n",
      "weighted avg       0.56      0.55      0.55       694\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.36      0.43       401\n",
      "           1       0.51      0.68      0.58       384\n",
      "\n",
      "    accuracy                           0.52       785\n",
      "   macro avg       0.52      0.52      0.51       785\n",
      "weighted avg       0.52      0.52      0.51       785\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.51      0.53       377\n",
      "           1       0.52      0.56      0.54       359\n",
      "\n",
      "    accuracy                           0.53       736\n",
      "   macro avg       0.53      0.53      0.53       736\n",
      "weighted avg       0.54      0.53      0.53       736\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.46      0.55       306\n",
      "           1       0.60      0.78      0.68       314\n",
      "\n",
      "    accuracy                           0.62       620\n",
      "   macro avg       0.64      0.62      0.61       620\n",
      "weighted avg       0.64      0.62      0.61       620\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.73      0.65       309\n",
      "           1       0.70      0.55      0.62       355\n",
      "\n",
      "    accuracy                           0.64       664\n",
      "   macro avg       0.64      0.64      0.63       664\n",
      "weighted avg       0.65      0.64      0.63       664\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.78      0.61       358\n",
      "           1       0.56      0.26      0.36       378\n",
      "\n",
      "    accuracy                           0.51       736\n",
      "   macro avg       0.53      0.52      0.48       736\n",
      "weighted avg       0.53      0.51      0.48       736\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.01      0.02       346\n",
      "           1       0.53      0.96      0.68       399\n",
      "\n",
      "    accuracy                           0.52       745\n",
      "   macro avg       0.35      0.49      0.35       745\n",
      "weighted avg       0.37      0.52      0.37       745\n",
      "\n",
      "               svc        rf     dummy       knn       ann       gbm   xgboost\n",
      "0cbaf29f  0.536074  0.509925  0.326395  0.464650  0.518691  0.517282  0.504048\n",
      "239022dd  0.423672  0.503873  0.352126  0.481059  0.522107  0.511590  0.516984\n",
      "5dbdbc27  0.628627  0.548984  0.326214  0.577704  0.584793  0.501309  0.540939\n",
      "67da2976  0.469062  0.507145  0.328486  0.541234  0.601302  0.465028  0.480727\n",
      "7f2c0be7  0.338129  0.533863  0.327854  0.539299  0.604529  0.582738  0.546798\n",
      "86a4a2ac  0.500938  0.613097  0.336188  0.533153  0.569517  0.624508  0.611168\n",
      "992cdda3  0.547204  0.634797  0.348381  0.546513  0.543175  0.612402  0.570665\n",
      "b07e0a64  0.514267  0.484451  0.339318  0.514472  0.531224  0.532477  0.505452\n",
      "b86bd471  0.390954  0.349879  0.348776  0.479317  0.440206  0.391005  0.392191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Get unique subjects\n",
    "unique_subjects = df['pid'].unique()\n",
    "\n",
    "# Initialize a DataFrame to store F1 scores for each participant and model\n",
    "f1_scores_df = pd.DataFrame(index=unique_subjects, columns=['svc', 'rf', 'dummy'])\n",
    "\n",
    "for p in unique_subjects:\n",
    "    # Filter the dataset based on the subjects in each set\n",
    "    train_data = df[df['pid'] != p]\n",
    "    test_data = df[df['pid'] == p]\n",
    "\n",
    "    # Extract features (brain data) and target variable\n",
    "    X_train = train_data.filter(like=\"ch\", axis=1)\n",
    "    y_train = train_data['workload']\n",
    "    y_train = y_train.replace({0: 0, 3: 1})\n",
    "    \n",
    "\n",
    "    X_test = test_data.filter(like=\"ch\", axis=1)\n",
    "    y_test = test_data['workload']\n",
    "    y_test = y_test.replace({0: 0, 3: 1})\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "      \n",
    "    models = {\n",
    "        'svc': SVC(), \n",
    "        'rf': RandomForestClassifier(), \n",
    "        'dummy': DummyClassifier(strategy=\"most_frequent\"), \n",
    "        'knn': KNeighborsClassifier(n_neighbors=5),  # Start with 5 neighbors, \n",
    "        'ann': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=10000),  # Simple 2-layer feedforward network,\n",
    "        'gbm': GradientBoostingClassifier(), \n",
    "        #'lightgbm': lgb.LGBMClassifier(), \n",
    "        'xgboost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')  # To avoid warning\n",
    "    }\n",
    "\n",
    "    for modelname in models.keys():\n",
    "        model = models[modelname]\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        preds = model.predict(X_test)    \n",
    "        \n",
    "        # Calculate macro average F1 score and store in the DataFrame\n",
    "        f1_macro = f1_score(y_test, preds, average='macro')\n",
    "        f1_scores_df.loc[p, modelname] = f1_macro\n",
    "\n",
    "        if modelname == 'rf':\n",
    "            print(classification_report(y_test, preds))\n",
    "\n",
    "print(f1_scores_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           stacked        rf     dummy       svc\n",
      "0cbaf29f   0.38843  0.267327   0.38843  0.388430\n",
      "239022dd  0.293478  0.368932  0.368932  0.368932\n",
      "5dbdbc27     0.344  0.322314     0.344  0.344000\n",
      "67da2976  0.373913  0.287129  0.373913  0.373913\n",
      "7f2c0be7  0.335484  0.331169  0.335484  0.335484\n",
      "86a4a2ac  0.397849  0.253333  0.397849  0.397849\n",
      "992cdda3     0.344  0.322314     0.344  0.344000\n",
      "b07e0a64  0.343511  0.322835  0.343511  0.343511\n",
      "b86bd471  0.330579  0.330579  0.336066  0.336066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Get unique subjects\n",
    "unique_subjects = df['pid'].unique()\n",
    "\n",
    "# Initialize a DataFrame to store F1 scores for each participant and model\n",
    "f1_scores_df = pd.DataFrame(index=unique_subjects, columns=['stacked', 'rf', 'dummy'])\n",
    "\n",
    "# Outer loop: Participants reserved for testing\n",
    "for test_p in unique_subjects:\n",
    "    \n",
    "    # Filter the dataset for the test participant\n",
    "    test_data = df[df['pid'] == test_p]\n",
    "    X_test = test_data.filter(like=\"ch\", axis=1)\n",
    "    y_test = test_data['workload']\n",
    "\n",
    "    # Inner loop: Participants reserved for training the meta-model\n",
    "    for meta_p in unique_subjects:\n",
    "        \n",
    "        if meta_p == test_p:\n",
    "            continue  # Skip if meta participant is same as test participant\n",
    "\n",
    "        # Split data\n",
    "        meta_data = df[df['pid'] == meta_p]\n",
    "        train_data = df[(df['pid'] != test_p) & (df['pid'] != meta_p)]\n",
    "\n",
    "        # Extract features and target variable\n",
    "        X_train = train_data.filter(like=\"ch\", axis=1)\n",
    "        y_train = train_data['workload']\n",
    "\n",
    "        X_meta = meta_data.filter(like=\"ch\", axis=1)\n",
    "        y_meta = meta_data['workload']\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_meta = scaler.transform(X_meta)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        models = { \n",
    "                    'rf': RandomForestClassifier(),                 \n",
    "                    'knn': KNeighborsClassifier(n_neighbors=5),  # Start with 5 neighbors, \n",
    "                    'ann': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=10000),  # Simple 2-layer feedforward network,\n",
    "                    'gbm': GradientBoostingClassifier(),                     \n",
    "                }\n",
    "        meta_features = []\n",
    "\n",
    "        # Train base models and get predictions (meta-features) for meta-data\n",
    "        for modelname in models.keys():\n",
    "            model = models[modelname]\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict_proba(X_meta)[:, 1]  # Use predicted probabilities as meta-features\n",
    "            meta_features.append(preds)\n",
    "\n",
    "        # Prepare meta-feature matrix for meta-model training\n",
    "        X_meta_features = np.column_stack(meta_features)\n",
    "\n",
    "        # Train the meta-model\n",
    "        meta_model = LogisticRegression(max_iter=10000)\n",
    "        meta_model.fit(X_meta_features, y_meta)\n",
    "\n",
    "        # Predict using base models on test data and use meta-model for final prediction\n",
    "        test_meta_features = []\n",
    "        for modelname in models.keys():\n",
    "            model = models[modelname]\n",
    "            preds = model.predict_proba(X_test)[:, 1]\n",
    "            test_meta_features.append(preds)\n",
    "        \n",
    "        X_test_meta_features = np.column_stack(test_meta_features)\n",
    "        final_preds = meta_model.predict(X_test_meta_features)\n",
    "\n",
    "        # Calculate F1 score for the stacked model\n",
    "        f1_stacked = f1_score(y_test, final_preds, average='macro')\n",
    "        f1_scores_df.loc[test_p, 'stacked'] = f1_stacked\n",
    "\n",
    "        # Evaluate base models (as before)\n",
    "        for modelname in models.keys():\n",
    "            model = models[modelname]\n",
    "            preds = model.predict(X_test)\n",
    "            f1 = f1_score(y_test, preds, average='macro')\n",
    "            f1_scores_df.loc[test_p, modelname] = f1\n",
    "\n",
    "print(f1_scores_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
